{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Analysis  \n",
    "##### All features are wrapped in python functions (use Run All to define all functions and launch them individually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "import numpy as np\n",
    "import datetime\n",
    "import plotly.graph_objects as go\n",
    "import talib as ta \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RUN this feature only once if you do NOT have historical data  \n",
    "All price data will be stored in a CSV file under (CSV folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get historical data from Yahoo finance and store as a CSV file\n",
    "# Also cumulates symbols that are not available on Yahoo Finance for further investigation\n",
    "# TODO: Modify this function to pass start and end date for extraction if data before 2014 is required\n",
    "def yahoo_to_csv(ticker, exchange):\n",
    "    start_date = \"2014-01-01\"\n",
    "    end_date   = str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "    if exchange == \"tsx\":\n",
    "        yahoo_symbol = ticker.replace(\".\", \"-\") + \".TO\"\n",
    "    else:\n",
    "        yahoo_symbol = ticker.replace(\".\", \"-\") + \".V\"\n",
    "\n",
    "    try:\n",
    "        data = pdr.DataReader(yahoo_symbol, \"yahoo\", start_date, end_date)\n",
    "        data[\"Ticker\"] = ticker\n",
    "        data.index = pd.to_datetime(data.index)\n",
    "        data.to_csv(f\"CSV/{ticker}.csv\", index_label=\"Date\", mode=\"w\", date_format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to read Data from Yahoo : {e}\")\n",
    "        return None\n",
    "\n",
    "# yahoo_to_csv(\"SHOP\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Feature to extract history price data from TSX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Web scraper for TSX (when we can't get it from yahoo finance)\n",
    "import time\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_browser():\n",
    "    # Setup Selenium browser\n",
    "    CHROME_DRIVER_LOCATION = \"chromedriver.exe\"\n",
    "    service_object = Service(CHROME_DRIVER_LOCATION)\n",
    "\n",
    "    OPTIONS = webdriver.ChromeOptions()\n",
    "    OPTIONS.add_argument('--ignore-certicate-errors')\n",
    "    OPTIONS.add_argument('--incognito')\n",
    "    #OPTIONS.add_argument('--headless')\n",
    "    OPTIONS.add_experimental_option('excludeSwitches', ['enable-logging'])\n",
    "    \n",
    "    #self.driver = webdriver.Chrome(executable_path=CHROME_DRIVER_LOCATION,options=OPTIONS)\n",
    "    driver = webdriver.Chrome(service=service_object, options=OPTIONS)\n",
    "    WebDriverWait(driver, 10)\n",
    "\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def close_add(driver):\n",
    "    try:\n",
    "        close_ad_btn = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.ID, 'ssrt-close-anchor-button')))\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to close_ads \")  \n",
    "        return False \n",
    "\n",
    "    try:\n",
    "        close_ad_btn.click()\n",
    "        return True\n",
    "    except:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_page(driver):\n",
    "    # btn_next = driver.find_element(By.XPATH, \"//button[@data-testid='next-button']\")\n",
    "    try:\n",
    "        next_btn = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.XPATH, \"//button[@data-testid='next-button']\")))\n",
    "        next_btn.click()\n",
    "        #print(f\"Next button element found on page...\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"Next button element NOT FOUND :\")  \n",
    "        return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsx_to_csv(driver, ticker, num_pages):\n",
    "    url = f\"https://money.tmx.com/en/quote/{ticker}/trade-history?selectedTab=price-history\"\n",
    "    driver.get(url)\n",
    "    random_delay = random.randint(2, 6)\n",
    "    #print(f\"Random sleep delay : {random_delay}\")\n",
    "    time.sleep(random_delay)\n",
    "    ad_closed = close_add(driver)\n",
    "\n",
    "    column_names = [\"Date\", \"Open ($)\", \"High ($)\", \"Low ($)\", \"Close ($)\", \"VWAP ($)\", \"Change ($)\", \"Change (%)\", \"Volume\", \"Trade Value\", \"# Trades\"]\n",
    "    data_df = pd.DataFrame(columns=column_names)\n",
    "\n",
    "    if ad_closed:\n",
    "        # Loop through pages\n",
    "        for i in range(0, num_pages):\n",
    "            html_page = driver.page_source \n",
    "            try:\n",
    "                html_data = pd.read_html(html_page)\n",
    "            except:\n",
    "                html_data = []\n",
    "            \n",
    "            if len(html_data) == 0:\n",
    "                i = num_pages\n",
    "                prices_df = None\n",
    "            else:\n",
    "                prices_df = html_data[0]\n",
    "                if prices_df.empty:\n",
    "                    i = num_pages\n",
    "                else:\n",
    "                    data_df = data_df.append(prices_df)\n",
    "                    prices_df = None\n",
    "                    # click next page button\n",
    "                    next_page(driver)\n",
    "                    random_delay = random.randint(2, 6)\n",
    "                    #print(f\"Random sleep delay NEXT PAGE : {random_delay}\")\n",
    "                    time.sleep(random_delay)\n",
    "\n",
    "        if not data_df.empty:\n",
    "            data_df.index = pd.to_datetime(data_df[\"Date\"], infer_datetime_format=True)\n",
    "            data_df.drop(columns=[\"Date\",\"VWAP ($)\",\"Change ($)\",\"Change (%)\",\"Trade Value\",\"# Trades\"], inplace=True)\n",
    "            data_df = data_df.rename(columns={'Open ($)': 'Open', 'High ($)': 'High', 'Low ($)': 'Low', 'Close ($)': 'Close'})\n",
    "            data_df[\"Adj Close\"] = -1\n",
    "            data_df[\"Ticker\"] = ticker\n",
    "            data_df.to_csv(f\"TSXCSV/{ticker}.csv\", index_label=\"Date\", mode=\"w\", date_format=\"%Y-%m-%d %H:%M:%S\")\n",
    "            return data_df\n",
    "        else:\n",
    "            print(f\"No data scrapped - no prices found, {ticker}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"No data scrapped - problem with ads, {ticker}\")\n",
    "        return None\n",
    "\n",
    "# driver = open_browser()\n",
    "# p1 = tsx_to_csv(driver, \"RY.PR.M\", 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loop_through_missing_symbols(amount):\n",
    "    notfound_symbols = pd.read_csv(\"notfound.csv\", header=None)\n",
    "    symbols_list = notfound_symbols[0].tolist()\n",
    "    start_index = 0\n",
    "    step = amount\n",
    "    driver = open_browser()\n",
    "    for symbol in symbols_list[start_index:start_index+step]:\n",
    "        p1 = tsx_to_csv(driver, symbol, 100)\n",
    "        print(f\"Symbol : {symbol}\")\n",
    "    \n",
    "# loop_through_missing_symbols(50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export SQLite3 Prices to CSV file for github push using yearly export\n",
    "def yearly_prices_to_csv(year):\n",
    "    #year=\"2022\"\n",
    "    conn = sqlite3.connect(\"TSX_Quality.sqlite\")\n",
    "    sql = f\"SELECT * FROM 'prices_daily' WHERE Date LIKE '{year}%' ORDER BY ticker ASC, Date DESC\"\n",
    "    data = pd.read_sql_query(sql, conn)\n",
    "    #data.drop(labels=\"index\", axis=1, inplace=True)\n",
    "    #data[\"Date\"] = pd.to_datetime(data[\"Date\"], infer_datetime_format=True)\n",
    "    #data[\"Date\"] = data[\"Date\"].dt.date\n",
    "    data.to_csv(f\"prices_{year}.csv\", index=False)\n",
    "\n",
    "#yearly_prices_to_csv(\"2013\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return a Dataframe with all symbols available in database\n",
    "def get_all_symbols():\n",
    "    \"\"\" Get all symbols in database as a DataFrame \"\"\"\n",
    "    conn = sqlite3.connect(\"TSX_Prices.sqlite\")\n",
    "    sql = f\"SELECT * FROM symbols ORDER BY ticker\"\n",
    "    data = pd.read_sql_query(sql, conn, index_col=\"ticker\")\n",
    "    data.drop(labels=[\"index\", \"url\", \"yahoo\"], axis=1, inplace=True )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavy function to retreive all prices from database (more than 5 million rows, takes many seconds to execute)\n",
    "def get_all_prices():\n",
    "    conn = sqlite3.connect(\"TSX_Quality.sqlite\")\n",
    "    sql = f\"SELECT * FROM prices_daily ORDER BY UPPER(Ticker) ASC, Date ASC\"\n",
    "    prices = pd.read_sql_query(sql, conn, index_col=\"Date\")\n",
    "    prices.index = pd.to_datetime(prices.index)\n",
    "    #prices = pd.read_sql_query(sql, conn, index_col=\"ticker\")\n",
    "    #prices.drop(\"index\", axis=1, inplace=True)\n",
    "    \n",
    "    return prices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_dataframe(folder, file):\n",
    "    data = pd.read_csv(f\"{folder}/{file}\", index_col=\"Date\")\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "    data = data[[\"Ticker\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]]\n",
    "    return data\n",
    "\n",
    "def insert_new_prices_in_DB(new_prices, db_prices, conn):\n",
    "    ticker = new_prices[\"Ticker\"].values[0]\n",
    "    existing_prices = db_prices.loc[db_prices[\"Ticker\"] == ticker]\n",
    "    filter = new_prices.index.isin(existing_prices.index)\n",
    "    new_prices.drop(new_prices[filter].index, inplace = True)\n",
    "    #conn = sqlite3.connect(\"TSX_Quality.sqlite\")    \n",
    "    new_prices.to_sql(\"Prices_Daily\", conn, if_exists='append', index=True)\n",
    "    return new_prices\n",
    "\n",
    "def loop_through_local_csv(existing_prices, conn, folder):\n",
    "    csv_files = os.listdir(f\"{folder}\")\n",
    "    for file in csv_files:\n",
    "        new_data = csv_to_dataframe(folder, file)\n",
    "        insert_new_prices_in_DB(new_data, existing_prices, conn)\n",
    "        print(f\"Finished processing : {file}\")\n",
    "\n",
    "# conn1 = sqlite3.connect(\"TSX_Quality.sqlite\")\n",
    "# sql = f\"SELECT * FROM prices_daily ORDER BY Ticker ASC, Date ASC\"\n",
    "# db_prices = pd.read_sql_query(sql, conn1, index_col=\"Date\")\n",
    "# loop_through_local_csv(db_prices, conn1, \"CSV\")\n",
    "\n",
    "conn1 = sqlite3.connect(\"TSX_Quality.sqlite\")\n",
    "db_prices = get_all_prices()\n",
    "loop_through_local_csv(db_prices, conn1, \"TSXCSV\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell to loop through all symbols and extract price data from yahoo\n",
    "def loop_through_symbols_on_yahoo():\n",
    "    not_found_on_yahoo = []\n",
    "    df = get_all_symbols()\n",
    "    df[\"YahooExists\"] = False\n",
    "    #df_t = df[40:70]\n",
    "    df_t = df\n",
    "\n",
    "    for index, row in df_t.iterrows():\n",
    "        symbol = index\n",
    "        exchange = row[\"exchange\"]\n",
    "        result = yahoo_to_csv(symbol, exchange)\n",
    "        if result is not None:\n",
    "            df.at[symbol, \"YahooExists\"] = True\n",
    "        else:\n",
    "            not_found_on_yahoo.append(symbol)\n",
    "\n",
    "    print(not_found_on_yahoo)\n",
    "    notfound_df = pd.DataFrame(not_found_on_yahoo)\n",
    "    notfound_df.to_csv(\"notfoundonyahoo.csv\", mode=\"w\", index=False, header=False )\n",
    "# 3634 elements from yahoo in 1:11 hours\n",
    "\n",
    "#loop_through_symbols_on_yahoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA QUALITY INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the first price data for every ticker (to help in finding previous date for GAP analysis)\n",
    "# Prices must be sorted by ascending  ticker symbol and ascending dates\n",
    "# For every ticker+date combination, insert the date of the previous price data fo rthe same ticker (to calculate the number of days between data and detect missing prices)\n",
    "def detect_missing_prices(prices):\n",
    "    prices[\"new_ticker\"] = np.where(prices[\"Ticker\"] != prices[\"Ticker\"].shift(1), \"New\", \"\")\n",
    "    prices[\"cur_date\"]  = pd.to_datetime(prices.index, format=\"%Y-%m-%d\", errors='coerce')\n",
    "    prices[\"prev_date\"] = pd.to_datetime(np.where(prices[\"new_ticker\"] != \"New\", prices[\"cur_date\"].shift(1), None), format=\"%Y-%m-%d\", errors='coerce')\n",
    "\n",
    "    # Calculate date gaps in prices using succesive dates for tickers in database\n",
    "    prices[\"GAP\"] = prices[\"cur_date\"] - prices[\"prev_date\"]\n",
    "    prices[\"missing\"] = prices[\"GAP\"] > datetime.timedelta(days=5)\n",
    "\n",
    "    \n",
    "# Show date GAPS for a specific symbol\n",
    "def show_missing_prices(prices, ticker=None):\n",
    "    if ticker is None:\n",
    "        filter = (prices[\"missing\"] == True)\n",
    "    else:\n",
    "        filter = (prices[\"missing\"] == True) & (prices[\"Ticker\"] == ticker)\n",
    "    \n",
    "    missing_data = prices.loc[filter]\n",
    "    return missing_data\n",
    "\n",
    "prices = get_all_prices()\n",
    "detect_missing_prices(prices)\n",
    "missing_df = show_missing_prices(prices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>new_ticker</th>\n",
       "      <th>cur_date</th>\n",
       "      <th>prev_date</th>\n",
       "      <th>GAP</th>\n",
       "      <th>missing</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-06-01</th>\n",
       "      <td>SBC.PR.A</td>\n",
       "      <td>9.74</td>\n",
       "      <td>9.81</td>\n",
       "      <td>9.74</td>\n",
       "      <td>9.75</td>\n",
       "      <td>24000.0</td>\n",
       "      <td></td>\n",
       "      <td>2020-06-01</td>\n",
       "      <td>2019-11-22</td>\n",
       "      <td>192 days</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-09-20</th>\n",
       "      <td>WN.PR.C</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.03</td>\n",
       "      <td>25.0</td>\n",
       "      <td>25.03</td>\n",
       "      <td>800.0</td>\n",
       "      <td></td>\n",
       "      <td>2016-09-20</td>\n",
       "      <td>2016-05-06</td>\n",
       "      <td>137 days</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-05-09</th>\n",
       "      <td>SBC.PR.A</td>\n",
       "      <td>10.07</td>\n",
       "      <td>10.07</td>\n",
       "      <td>10.07</td>\n",
       "      <td>10.07</td>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "      <td>2016-05-09</td>\n",
       "      <td>2015-12-24</td>\n",
       "      <td>137 days</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-02-28</th>\n",
       "      <td>UNC.PR.B</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>24.333</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>2019-02-28</td>\n",
       "      <td>2018-11-09</td>\n",
       "      <td>111 days</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-16</th>\n",
       "      <td>RY.PR.J</td>\n",
       "      <td>24.32</td>\n",
       "      <td>24.51</td>\n",
       "      <td>24.32</td>\n",
       "      <td>24.51</td>\n",
       "      <td>6840.0</td>\n",
       "      <td></td>\n",
       "      <td>2015-07-16</td>\n",
       "      <td>2015-03-27</td>\n",
       "      <td>111 days</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-03-31</th>\n",
       "      <td>HUL.U</td>\n",
       "      <td>9.34070014953613</td>\n",
       "      <td>9.34070014953613</td>\n",
       "      <td>9.34070014953613</td>\n",
       "      <td>9.34070014953613</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>2015-03-31</td>\n",
       "      <td>2015-03-25</td>\n",
       "      <td>6 days</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-07-30</th>\n",
       "      <td>HTB</td>\n",
       "      <td>51.2299995422363</td>\n",
       "      <td>51.2299995422363</td>\n",
       "      <td>51.1399993896484</td>\n",
       "      <td>51.1399993896484</td>\n",
       "      <td>0.0</td>\n",
       "      <td></td>\n",
       "      <td>2015-07-30</td>\n",
       "      <td>2015-07-24</td>\n",
       "      <td>6 days</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-09</th>\n",
       "      <td>HTB</td>\n",
       "      <td>47.75</td>\n",
       "      <td>47.75</td>\n",
       "      <td>47.5099983215332</td>\n",
       "      <td>47.6100006103516</td>\n",
       "      <td>500.0</td>\n",
       "      <td></td>\n",
       "      <td>2015-06-09</td>\n",
       "      <td>2015-06-03</td>\n",
       "      <td>6 days</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-28</th>\n",
       "      <td>AEC</td>\n",
       "      <td>0.379999995231628</td>\n",
       "      <td>0.449999988079071</td>\n",
       "      <td>0.370000004768372</td>\n",
       "      <td>0.370000004768372</td>\n",
       "      <td>57900.0</td>\n",
       "      <td></td>\n",
       "      <td>2017-12-28</td>\n",
       "      <td>2017-12-22</td>\n",
       "      <td>6 days</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-06-03</th>\n",
       "      <td>PHW</td>\n",
       "      <td>20.8799991607666</td>\n",
       "      <td>20.8799991607666</td>\n",
       "      <td>20.8799991607666</td>\n",
       "      <td>20.8799991607666</td>\n",
       "      <td>100.0</td>\n",
       "      <td></td>\n",
       "      <td>2015-06-03</td>\n",
       "      <td>2015-05-28</td>\n",
       "      <td>6 days</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1368 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Ticker               Open               High                Low  \\\n",
       "Date                                                                            \n",
       "2020-06-01  SBC.PR.A               9.74               9.81               9.74   \n",
       "2016-09-20   WN.PR.C               25.0              25.03               25.0   \n",
       "2016-05-09  SBC.PR.A              10.07              10.07              10.07   \n",
       "2019-02-28  UNC.PR.B                  -                  -                  -   \n",
       "2015-07-16   RY.PR.J              24.32              24.51              24.32   \n",
       "...              ...                ...                ...                ...   \n",
       "2015-03-31     HUL.U   9.34070014953613   9.34070014953613   9.34070014953613   \n",
       "2015-07-30       HTB   51.2299995422363   51.2299995422363   51.1399993896484   \n",
       "2015-06-09       HTB              47.75              47.75   47.5099983215332   \n",
       "2017-12-28       AEC  0.379999995231628  0.449999988079071  0.370000004768372   \n",
       "2015-06-03       PHW   20.8799991607666   20.8799991607666   20.8799991607666   \n",
       "\n",
       "                        Close   Volume new_ticker   cur_date  prev_date  \\\n",
       "Date                                                                      \n",
       "2020-06-01               9.75  24000.0            2020-06-01 2019-11-22   \n",
       "2016-09-20              25.03    800.0            2016-09-20 2016-05-06   \n",
       "2016-05-09              10.07    100.0            2016-05-09 2015-12-24   \n",
       "2019-02-28             24.333      0.0            2019-02-28 2018-11-09   \n",
       "2015-07-16              24.51   6840.0            2015-07-16 2015-03-27   \n",
       "...                       ...      ...        ...        ...        ...   \n",
       "2015-03-31   9.34070014953613      0.0            2015-03-31 2015-03-25   \n",
       "2015-07-30   51.1399993896484      0.0            2015-07-30 2015-07-24   \n",
       "2015-06-09   47.6100006103516    500.0            2015-06-09 2015-06-03   \n",
       "2017-12-28  0.370000004768372  57900.0            2017-12-28 2017-12-22   \n",
       "2015-06-03   20.8799991607666    100.0            2015-06-03 2015-05-28   \n",
       "\n",
       "                GAP  missing  \n",
       "Date                          \n",
       "2020-06-01 192 days     True  \n",
       "2016-09-20 137 days     True  \n",
       "2016-05-09 137 days     True  \n",
       "2019-02-28 111 days     True  \n",
       "2015-07-16 111 days     True  \n",
       "...             ...      ...  \n",
       "2015-03-31   6 days     True  \n",
       "2015-07-30   6 days     True  \n",
       "2015-06-09   6 days     True  \n",
       "2017-12-28   6 days     True  \n",
       "2015-06-03   6 days     True  \n",
       "\n",
       "[1368 rows x 11 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#missing_df\n",
    "missing_df.sort_values(by='GAP', ascending=False)\n",
    "#missing_df.sort_values(by='GAP', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter = prices[\"new_ticker\"] == \"New\"\n",
    "#prices.loc[filter]\n",
    "# df[\"Trend\"] = np.where(df[\"Close\"] > df[\"SMA200\"], \"Up\", \"Down\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6ea743d4123cf0f72c1a3e7afb768a545bcfd9cdf4233ff0f334085311ff027"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
