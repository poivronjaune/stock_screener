{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "import numpy as np\n",
    "import datetime\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_symbols():\n",
    "    \"\"\" Get all symbols in database as a DataFrame \"\"\"\n",
    "    conn = sqlite3.connect(\"TSX_Prices.sqlite\")\n",
    "    sql = f\"SELECT * FROM symbols ORDER BY ticker\"\n",
    "    data = pd.read_sql_query(sql, conn, index_col=\"ticker\")\n",
    "    data.drop(labels=[\"index\", \"url\", \"yahoo\"], axis=1, inplace=True )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yahoo_to_csv(ticker, exchange):\n",
    "    start_date = \"2014-01-01\"\n",
    "    end_date   = str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "    if exchange == \"tsx\":\n",
    "        yahoo_symbol = ticker.replace(\".\", \"-\") + \".TO\"\n",
    "    else:\n",
    "        yahoo_symbol = ticker.replace(\".\", \"-\") + \".V\"\n",
    "\n",
    "    try:\n",
    "        data = pdr.DataReader(yahoo_symbol, \"yahoo\", start_date, end_date)\n",
    "        data[\"Ticker\"] = ticker\n",
    "        data.index = pd.to_datetime(data.index)\n",
    "        data.to_csv(f\"CSV/{ticker}.csv\", index_label=\"Date\", mode=\"w\", date_format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to read Data from Yahoo : {e}\")\n",
    "        return None\n",
    "\n",
    "# yahoo_to_csv(\"SHOP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notfound = []\n",
    "df = get_all_symbols()\n",
    "df[\"YahooExists\"] = False\n",
    "#df_t = df[40:70]\n",
    "df_t = df\n",
    "\n",
    "for index, row in df_t.iterrows():\n",
    "    symbol = index\n",
    "    exchange = row[\"exchange\"]\n",
    "    result = yahoo_to_csv(symbol, exchange)\n",
    "    if result is not None:\n",
    "        df.at[symbol, \"YahooExists\"] = True\n",
    "    else:\n",
    "        notfound.append(symbol)\n",
    "\n",
    "print(notfound)\n",
    "notfound_df = pd.DataFrame(notfound)\n",
    "notfound_df.to_csv(\"notfound.csv\", mode=\"w\", index=False, header=False )\n",
    "# 3634 elements from yahoo in 1:11 hours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_prices():\n",
    "    conn = sqlite3.connect(\"TSX_Prices.sqlite\")\n",
    "    sql = f\"SELECT * FROM prices_daily ORDER BY UPPER(Ticker) ASC, Date ASC\"\n",
    "    prices = pd.read_sql_query(sql, conn, index_col=\"Date\")\n",
    "    #prices = pd.read_sql_query(sql, conn, index_col=\"ticker\")\n",
    "    prices.drop(\"index\", axis=1, inplace=True)\n",
    "    \n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conn = sqlite3.connect(\"TSX_Prices.sqlite\")\n",
    "# sql = f\"SELECT * FROM prices_daily ORDER BY Ticker ASC, Date ASC\"\n",
    "# prices = pd.read_sql_query(sql, conn, index_col=\"Date\")\n",
    "# prices.drop(\"index\", axis=1, inplace=True)\n",
    "prices = get_all_prices()\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add some indicators for Data Quality Analysis\n",
    "\n",
    "# Identify the first price data for every ticker (to help in finding previous date for GAP analysis)\n",
    "prices[\"new_ticker\"] = np.where(prices[\"Ticker\"] != prices[\"Ticker\"].shift(1), \"New\", \"\")\n",
    "prices[\"cur_date\"]  = pd.to_datetime(prices.index, format=\"%Y-%m-%d\", errors='coerce')\n",
    "prices[\"prev_date\"] = pd.to_datetime(np.where(prices[\"new_ticker\"] != \"New\", prices[\"cur_date\"].shift(1), None), format=\"%Y-%m-%d\", errors='coerce')\n",
    "\n",
    "# Calculate data gaps in prices using succesive dates for tickers in database\n",
    "prices[\"GAP\"] = prices[\"cur_date\"] - prices[\"prev_date\"]\n",
    "prices[\"missing\"] = prices[\"GAP\"] > datetime.timedelta(days=5)\n",
    "\n",
    "#filter = prices[\"new_ticker\"] == \"New\"\n",
    "#prices.loc[filter]\n",
    "# df[\"Trend\"] = np.where(df[\"Close\"] > df[\"SMA200\"], \"Up\", \"Down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = (prices[\"missing\"] == True) & (prices[\"Ticker\"] == \"SHOP\")\n",
    "prices.loc[filter]"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6ea743d4123cf0f72c1a3e7afb768a545bcfd9cdf4233ff0f334085311ff027"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
