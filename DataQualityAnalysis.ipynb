{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Quality Analysis  \n",
    "##### All features are wrapped in python functions (use Run All to define all functions and launch them individually)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "import numpy as np\n",
    "import datetime\n",
    "import plotly.graph_objects as go\n",
    "import talib as ta "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RUN this feature only once if you do NOT have historical data  \n",
    "All price data will stored in a CSV file under (CSV folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get historical data from Yahoo finance and store as a CSV file\n",
    "# Also cumulates symbols that are not available on Yahoo Finance for further investigation\n",
    "# TODO: Modify this function to pass start and end date for extraction if data before 2014 is required\n",
    "def yahoo_to_csv(ticker, exchange):\n",
    "    start_date = \"2014-01-01\"\n",
    "    end_date   = str(datetime.datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "    if exchange == \"tsx\":\n",
    "        yahoo_symbol = ticker.replace(\".\", \"-\") + \".TO\"\n",
    "    else:\n",
    "        yahoo_symbol = ticker.replace(\".\", \"-\") + \".V\"\n",
    "\n",
    "    try:\n",
    "        data = pdr.DataReader(yahoo_symbol, \"yahoo\", start_date, end_date)\n",
    "        data[\"Ticker\"] = ticker\n",
    "        data.index = pd.to_datetime(data.index)\n",
    "        data.to_csv(f\"CSV/{ticker}.csv\", index_label=\"Date\", mode=\"w\", date_format=\"%Y-%m-%d %H:%M:%S\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        print(f\"Unable to read Data from Yahoo : {e}\")\n",
    "        return None\n",
    "\n",
    "# yahoo_to_csv(\"SHOP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export SQLite3 Prices to CSV file for github push using yearly export\n",
    "def yearly_prices_to_csv(year):\n",
    "    #year=\"2022\"\n",
    "    conn = sqlite3.connect(\"TSX_Quality.sqlite\")\n",
    "    sql = f\"SELECT * FROM 'prices_daily' WHERE Date LIKE '{year}%' ORDER BY ticker ASC, Date DESC\"\n",
    "    data = pd.read_sql_query(sql, conn)\n",
    "    #data.drop(labels=\"index\", axis=1, inplace=True)\n",
    "    #data[\"Date\"] = pd.to_datetime(data[\"Date\"], infer_datetime_format=True)\n",
    "    #data[\"Date\"] = data[\"Date\"].dt.date\n",
    "    data.to_csv(f\"prices_{year}.csv\", index=False)\n",
    "\n",
    "# yearly_prices_to_csv(\"2022\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def csv_to_dataframe(file):\n",
    "    data = pd.read_csv(f\"CSV/{file}\", index_col=\"Date\")\n",
    "    data.index = pd.to_datetime(data.index)\n",
    "    data = data[[\"Ticker\",\"Open\",\"High\",\"Low\",\"Close\",\"Volume\"]]\n",
    "    return data\n",
    "\n",
    "def insert_new_prices_in_DB(new_prices, db_prices, conn):\n",
    "    ticker = new_prices[\"Ticker\"].values[0]\n",
    "    existing_prices = db_prices.loc[db_prices[\"Ticker\"] == ticker]\n",
    "    filter = new_prices.index.isin(existing_prices.index)\n",
    "    new_prices.drop(new_prices[filter].index, inplace = True)\n",
    "    #conn = sqlite3.connect(\"TSX_Quality.sqlite\")    \n",
    "    new_prices.to_sql(\"Prices_Daily\", conn, if_exists='append', index=True)\n",
    "    return new_prices\n",
    "\n",
    "\n",
    "def loop_through_local_csv(existing_prices, conn):\n",
    "    csv_files = os.listdir(\"CSV\")\n",
    "    for file in csv_files:\n",
    "        new_data = csv_to_dataframe(file)\n",
    "        insert_new_prices_in_DB(new_data, existing_prices, conn)\n",
    "        print(f\"Finished processing : {file}\")\n",
    "\n",
    "# conn1 = sqlite3.connect(\"TSX_Quality.sqlite\")\n",
    "# sql = f\"SELECT * FROM prices_daily ORDER BY Ticker ASC, Date ASC\"\n",
    "# db_prices = pd.read_sql_query(sql, conn1, index_col=\"Date\")\n",
    "# loop_through_local_csv(db_prices, conn1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return a Dataframe with all symbols available in database\n",
    "def get_all_symbols():\n",
    "    \"\"\" Get all symbols in database as a DataFrame \"\"\"\n",
    "    conn = sqlite3.connect(\"TSX_Prices.sqlite\")\n",
    "    sql = f\"SELECT * FROM symbols ORDER BY ticker\"\n",
    "    data = pd.read_sql_query(sql, conn, index_col=\"ticker\")\n",
    "    data.drop(labels=[\"index\", \"url\", \"yahoo\"], axis=1, inplace=True )\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heavy function to retreive all prices from database (more than 3 million rows, takes many seconds to execute)\n",
    "def get_all_prices():\n",
    "    conn = sqlite3.connect(\"TSX_Quality.sqlite\")\n",
    "    sql = f\"SELECT * FROM prices_daily ORDER BY UPPER(Ticker) ASC, Date ASC\"\n",
    "    prices = pd.read_sql_query(sql, conn, index_col=\"Date\")\n",
    "    prices.index = pd.to_datetime(prices.index)\n",
    "    #prices = pd.read_sql_query(sql, conn, index_col=\"ticker\")\n",
    "    #prices.drop(\"index\", axis=1, inplace=True)\n",
    "    \n",
    "    return prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell to loop through all symbols and extract price data\n",
    "def loop_through_symbols_on_yahoo():\n",
    "    not_found_on_yahoo = []\n",
    "    df = get_all_symbols()\n",
    "    df[\"YahooExists\"] = False\n",
    "    #df_t = df[40:70]\n",
    "    df_t = df\n",
    "\n",
    "    for index, row in df_t.iterrows():\n",
    "        symbol = index\n",
    "        exchange = row[\"exchange\"]\n",
    "        result = yahoo_to_csv(symbol, exchange)\n",
    "        if result is not None:\n",
    "            df.at[symbol, \"YahooExists\"] = True\n",
    "        else:\n",
    "            not_found_on_yahoo.append(symbol)\n",
    "\n",
    "    print(not_found_on_yahoo)\n",
    "    notfound_df = pd.DataFrame(not_found_on_yahoo)\n",
    "    notfound_df.to_csv(\"notfoundonyahoo.csv\", mode=\"w\", index=False, header=False )\n",
    "# 3634 elements from yahoo in 1:11 hours\n",
    "\n",
    "#loop_through_symbols_on_yahoo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA QUALITY INDICATORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify the first price data for every ticker (to help in finding previous date for GAP analysis)\n",
    "# Prices must be sorted by ascending  ticker symbol and ascending dates\n",
    "# For every ticker+date combination, insert the date of the previous price data fo rthe same ticker (to calculate the number of days between data and detect missing prices)\n",
    "def detect_missing_prices(prices):\n",
    "    prices[\"new_ticker\"] = np.where(prices[\"Ticker\"] != prices[\"Ticker\"].shift(1), \"New\", \"\")\n",
    "    prices[\"cur_date\"]  = pd.to_datetime(prices.index, format=\"%Y-%m-%d\", errors='coerce')\n",
    "    prices[\"prev_date\"] = pd.to_datetime(np.where(prices[\"new_ticker\"] != \"New\", prices[\"cur_date\"].shift(1), None), format=\"%Y-%m-%d\", errors='coerce')\n",
    "\n",
    "    # Calculate date gaps in prices using succesive dates for tickers in database\n",
    "    prices[\"GAP\"] = prices[\"cur_date\"] - prices[\"prev_date\"]\n",
    "    prices[\"missing\"] = prices[\"GAP\"] > datetime.timedelta(days=5)\n",
    "    \n",
    "# Show date GAPS for a specific symbol\n",
    "def show_missing_prices(prices, ticker=None):\n",
    "    if ticker is None:\n",
    "        filter = (prices[\"missing\"] == True)\n",
    "    else:\n",
    "        filter = (prices[\"missing\"] == True) & (prices[\"Ticker\"] == ticker)\n",
    "    \n",
    "    missing_data = prices.loc[filter]\n",
    "    return missing_data\n",
    "\n",
    "# prices = get_all_prices()\n",
    "# detect_missing_prices(prices)\n",
    "# missing_df = show_missing_prices(prices)\n",
    "# missing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter = prices[\"new_ticker\"] == \"New\"\n",
    "#prices.loc[filter]\n",
    "# df[\"Trend\"] = np.where(df[\"Close\"] > df[\"SMA200\"], \"Up\", \"Down\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run all data quality indicators\n",
    "\n",
    "# LOAD PRICES DATA AND RUN FEATURES FOR DATA QUALITY ANALYSIS\n",
    "# Heavy extraction will take many seconds (more than 3 million rows)\n",
    "# prices = get_all_prices()\n",
    "# detect_missing_prices(prices)\n",
    "\n",
    "# show_missing_prices()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6ea743d4123cf0f72c1a3e7afb768a545bcfd9cdf4233ff0f334085311ff027"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
